{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed61b749",
   "metadata": {},
   "source": [
    "# Sumário\n",
    "1. Inicialização\n",
    "    * Importando Bibliotecas\n",
    "    * Funções\n",
    "2. Pré-Processamento\n",
    "    * Seleção dos arquivos nos quais os dados se encontram\n",
    "    * Seleção do estado a ser analisado\n",
    "    * Teste de estacionalidade de Dickey Fuller\n",
    "    * Diferenciação da série e teste de estacionariedade na série diferenciada\n",
    "    * Autocorrelação Mensal\n",
    "3. Modelagem\n",
    "    * Pré-processamento e Divisão entre Treino e Teste\n",
    "    * Algoritmo Sarimax\n",
    "    * Seleção do modelo a ser executado baseado no estado em análise\n",
    "    * Métricas de Validação do Modelo\n",
    "4. Gráficos\n",
    "    * Gráfico com comportamento da variável a ser predita\n",
    "    * Gráfico com comportamento da variável a ser predita, da média móvel e do desvio padrão móvel\n",
    "    * Gráficos de decomposição da série\n",
    "    * Gráficos de diferenciação, autocorrelação (acf) e autocorrelação parcial (pacf)\n",
    "    * Gráfico Real vs Predito\n",
    "    * Gráfico com o comportamento do ano predito\n",
    "    * Gráfico com o comportamento da série original e predita\n",
    "5. Execução da função principal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d1c5",
   "metadata": {},
   "source": [
    "# Inicialização\n",
    "* Importando Bibliotecas\n",
    "* Funções\n",
    "\n",
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd7dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "## viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "## model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5e1d7",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398ff78",
   "metadata": {},
   "source": [
    "## Seleção dos arquivos nos quais os dados se encontram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afbfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_selection(uf, PATH):\n",
    "    \"\"\" Create the dataframe based in the state under analysis.\n",
    "\n",
    "        Args:\n",
    "            uf (string): The state under analysis.\n",
    "            PATH (string): The path where .csv files locate.\n",
    "\n",
    "        Returns:\n",
    "            A dataframe with the state under analysis.\n",
    "    \"\"\"   \n",
    "    sudeste = ['SP', 'RJ', 'MG', 'ES']\n",
    "    sul = ['PR', 'SC', 'RS']\n",
    "    centrooeste = ['DF', 'MT', 'MS', 'GO']\n",
    "    nordeste = ['PB', 'PE', 'RN', 'CE', 'SE', 'BA', 'AL']\n",
    "    \n",
    "    if(uf in sudeste):\n",
    "        # Coloque aqui o nome do arquivo referente a base de dados do sudeste\n",
    "        file_train = 'base_sudeste.csv'\n",
    "        header = 'ml_ca_energia_consumo_armarios_sudeste_atualizada.'\n",
    "        \n",
    "    elif(uf in sul):\n",
    "        # Coloque aqui o nome do arquivo referente a base de dados do sul\n",
    "        file_train = 'base_sul.csv'\n",
    "        header = 'ml_ca_energia_consumo_armarios_sul_atualizada.'\n",
    "        \n",
    "    elif(uf in centrooeste):\n",
    "        # Coloque aqui o nome do arquivo referente a base de dados do centrooeste\n",
    "        file_train = 'base_centrooeste_V2.csv'\n",
    "        header = 'ml_ca_energia_consumo_armarios_centrooeste_atualizada.'\n",
    "        \n",
    "    elif(uf in nordeste):\n",
    "        # Coloque aqui o nome do arquivo referente a base de dados do nordeste\n",
    "        file_train = 'base_nordeste_V2.csv'\n",
    "        header = 'ml_ca_energia_consumo_armarios_nordeste_atualizada.'\n",
    "        \n",
    "    df = pd.read_csv(PATH + file_train, sep = '|')\n",
    "    df = uf_selection(uf, df, 'consumoacumuladodomes_soma', header)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9656e0",
   "metadata": {},
   "source": [
    "## Seleção do estado a ser analisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9844c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf_selection(uf, dataset, target, pattern):\n",
    "    \"\"\" Create the dataframe based in the state wants to predict.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            uf (string): The state under analysis.\n",
    "            target (string): The target column that will be predict.\n",
    "            pattern (string): The state under analysis.\n",
    "\n",
    "        Returns:\n",
    "            A dataframe with the state under analysis.\n",
    "    \"\"\"   \n",
    "    dataset.columns = dataset.columns.str.replace(pattern, '')\n",
    "    dataset['mes'] = dataset['mes'].astype('string')\n",
    "    dataset['mes'] = dataset['mes'].apply(lambda x: pd.to_datetime(str(x) + '01'))\n",
    "    dataset = dataset[['mes', target]].loc[dataset['uf'] == uf]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cfdee",
   "metadata": {},
   "source": [
    "## Teste de estacionalidade de Dickey Fuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ab6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(dataset, output_file):\n",
    "    \"\"\" Performs Augmented Dickey Fuller test.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "\n",
    "        Returns:\n",
    "            The results of adf test.\n",
    "    \"\"\"   \n",
    "    \n",
    "    output_file.writelines('Resultado do Teste Dickey-Fuller:')\n",
    "    dftest = adfuller(dataset, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Teste', 'Valor p', '# de lags', '# de observações'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Valores Críticos ({})'.format(key)] = value\n",
    "   \n",
    "    output_file.writelines(str(dfoutput) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea3a95",
   "metadata": {},
   "source": [
    "## Diferenciação da série e teste de estacionariedade na série diferenciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308099d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serie_differentiation(dataset, target, output_file, PATH, uf):\n",
    "    \"\"\" Create serie's differentiation.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with serie's differentiation, the results of adf test in the new serie and differentiation data.\n",
    "    \"\"\"     \n",
    "     \n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    df_diff = np.diff(dataset[target])\n",
    "    plt.plot(df_diff)\n",
    "\n",
    "    output_file.writelines('\\n\\nSérie Diferenciada: ' + '\\n')\n",
    "    output_file.writelines(str(adf_test(df_diff, output_file))+ '\\n')\n",
    "    \n",
    "    plt.savefig(PATH + '/serie_differentiation_' + uf + '.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return df_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7180aed",
   "metadata": {},
   "source": [
    "## Autocorrelação Mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27594fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_lag(dataset, target, output_file):\n",
    "    \"\"\" Print autocorrelation based in 1, 3, 6, 9 and 12 months.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "            \n",
    "        Returns:\n",
    "            The autocorrelation based in 1, 3, 6, 9 and 12 months.\n",
    "    \"\"\"     \n",
    "     \n",
    "    output_file.writelines('\\n\\nAutocorrelação : ' + '\\n')\n",
    "    autocorrelation_lag1 = dataset[target].autocorr(lag=1)\n",
    "    output_file.writelines(\"Um mês: \" + str(autocorrelation_lag1) + '\\n')\n",
    "\n",
    "    autocorrelation_lag3 = dataset[target].autocorr(lag=3)\n",
    "    output_file.writelines(\"Três meses: \" + str(autocorrelation_lag3)+ '\\n')\n",
    "\n",
    "    autocorrelation_lag6 = dataset[target].autocorr(lag=6)\n",
    "    output_file.writelines(\"Seis meses: \" + str(autocorrelation_lag6)+ '\\n')\n",
    "\n",
    "    autocorrelation_lag9 = dataset[target].autocorr(lag=9)\n",
    "    output_file.writelines(\"Nove meses: \" + str(autocorrelation_lag9)+ '\\n')\n",
    "\n",
    "    autocorrelation_lag12 = dataset[target].autocorr(lag=12)\n",
    "    output_file.writelines(\"Doze meses: \" + str(autocorrelation_lag12)+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abc75d",
   "metadata": {},
   "source": [
    "## Pré-processamento e Divisão entre Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe2bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(dataset, target, start, period, frequency, date_split, date_end, output_file):\n",
    "    \"\"\" Pre processing and split the train and test data.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "            start (string): The start date to be fill with NaNs to be predict.\n",
    "            period (int): The number of months to be fill with NaNs to be predict.\n",
    "            frequency (string): The unit to by fill, i.e., 'M' for months.\n",
    "            date_split (datetime): The date used for threshold to split the train and test.\n",
    "            date_end (datetime): The end date used for test dataset.\n",
    "            normalization (boolean): True if normalization will used and False if not.\n",
    "            \n",
    "        Returns:\n",
    "            The dataset pre processed, start and end intervals, and train and test datasets.\n",
    "    \"\"\"     \n",
    "     \n",
    "    temp = pd.DataFrame(pd.date_range(start=start, periods=period, freq=frequency), columns=['mes'])\n",
    "    temp['mes'] = pd.to_datetime(temp['mes'].dt.strftime('%Y-%m-01'))\n",
    "    temp[target] = np.nan\n",
    "\n",
    "    df = pd.concat([dataset, temp]).reset_index(drop=True)\n",
    "    del temp\n",
    "\n",
    "    xtrain = df[df['mes'] < date_split]\n",
    "    xtest = df.loc[(df['mes'] >= date_split) & (df['mes'] <= date_end)]\n",
    "    \n",
    "    output_file.writelines('\\n\\nTrain interval: ' + str(xtrain['mes'].min().date()) + ' até ' + str(xtrain['mes'].max().date()))\n",
    "    output_file.writelines('\\nTest interval: ' + str(xtest['mes'].min().date()) + ' até ' + str(xtest['mes'].max().date()))\n",
    "\n",
    "    interval_start = xtest.index.min()\n",
    "    interval_end = xtest.index.max()\n",
    "\n",
    "    output_file.writelines('\\nTest interval: ' + str(interval_start) + ' até ' + str(interval_end))\n",
    "\n",
    "    xtrain.set_index('mes', inplace = True)\n",
    "    xtest.set_index('mes', inplace = True)\n",
    "    \n",
    "    return xtrain, xtest, interval_start, interval_end, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc6d10",
   "metadata": {},
   "source": [
    "## Algoritmo Sarimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233e9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax_algorithm(train_dataset, test_dataset, target, interval_start, interval_end, order, seasonal_order, normalization):\n",
    "    \"\"\" Execute sarimax algorithm.\n",
    "\n",
    "        Args:\n",
    "        train_dataset (array-like or iterable, shape=(n_samples,)): The time-series to which to fit the sarimax estimator.\n",
    "        test_dataset (object/spreadsheet): The test dataset under analysis.\n",
    "        target (string): The name of target column under analysis.\n",
    "        interval_start (int): The start index of the test interval.\n",
    "        interval_end (int): The end index of the test interval.\n",
    "        order (tuple): The (p,d,q) order of the model for the number of AR parameters, differences, and MA parameters. d must be an integer indicating the integration order of the process, while p and q may either be an integers indicating the AR and MA orders (so that all lags up to those orders are included) or else iterables giving specific AR and / or MA lags to include. Default is an AR(1) model: (1,0,0).\n",
    "        seasonal_order (tuple): The (P,D,Q,s) order of the seasonal component of the model for the AR parameters, differences, MA parameters, and periodicity. D must be an integer indicating the integration order of the process, while P and Q may either be an integers indicating the AR and MA orders (so that all lags up to those orders are included) or else iterables giving specific AR and / or MA lags to include. s is an integer giving the periodicity (number of periods in season), often it is 4 for quarterly data or 12 for monthly data. Default is no seasonal effect.\n",
    "        normalization (boolean): True if normalization will used and False if not.\n",
    "        \n",
    "        Returns:\n",
    "            The trained model and the predictions.\n",
    "    \"\"\"     \n",
    "    if(normalization == True):\n",
    "        x_train_scaled = train_dataset.copy()\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaler_data = scaler.fit_transform(x_train_scaled[target].values.reshape(-1, 1))\n",
    "        x_train_scaled[target] = scaler_data\n",
    "        xtrain = x_train_scaled.copy()\n",
    "    \n",
    "    else:\n",
    "        xtrain = train_dataset.copy()\n",
    "        \n",
    "        \n",
    "    sarimax = sm.tsa.statespace.SARIMAX(xtrain, order=order, seasonal_order=seasonal_order).fit()\n",
    "    \n",
    "    test_dataset['pred'] = sarimax.predict(start=interval_start, end=interval_end, dynamic=True)\n",
    "    \n",
    "    if(normalization == True):\n",
    "        scaler_data = scaler.inverse_transform(test_dataset['pred'].values.reshape(-1, 1))\n",
    "        test_dataset['pred'] = scaler_data\n",
    "\n",
    "    return sarimax, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f0e77",
   "metadata": {},
   "source": [
    "## Seleção do modelo a ser executado baseado no estado em análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c813070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf_models(uf, xtrain, xtest, target, interval_start, interval_end):\n",
    "    \"\"\" Select the parameters according to the state under analysis and execute sarimax model.\n",
    "\n",
    "        Args:\n",
    "            uf (string): The state under analysis.\n",
    "            xtrain (array-like or iterable, shape=(n_samples,)): The time-series to which to fit the sarimax estimator.\n",
    "            xtest (object/spreadsheet): The test dataset under analysis.\n",
    "            target (string): The name of target column under analysis.\n",
    "            interval_start (int): The start index of the test interval.\n",
    "            interval_end (int): The end index of the test interval.\n",
    "            \n",
    "        Returns:\n",
    "            The trained model and the predictions.\n",
    "    \"\"\"     \n",
    "    model_111_111 = ['RS', 'SC', 'MG', 'RJ', 'MT', 'GO', 'MS', 'CE']\n",
    "    model_011_011 = ['ES', 'AL']\n",
    "\n",
    "    uf_dict = {'SP': [(1, 1, 2),(0, 1, 1, 12)], \n",
    "               'BA': [(0, 1, 1),(1, 1, 0, 12)],\n",
    "               'PE': [(0, 1, 1),(0, 1, 0, 12)],\n",
    "               'RN': [(0, 1, 1),(2, 1, 0, 12)],\n",
    "               'SE': [(0, 1, 2),(1, 1, 0, 12)],\n",
    "               'PR': [(0, 1, 0),(0, 1, 2, 12)],\n",
    "               'DF': [(2, 1, 0),(0, 0, 0, 12)],\n",
    "               'PB': [(0, 1, 0),(0, 1, 0, 12)],\n",
    "    }\n",
    "\n",
    "    for i in model_111_111:\n",
    "        uf_dict[i] = [(1, 1, 1),(1, 1, 1, 12)]\n",
    "\n",
    "    for i in model_011_011:\n",
    "        uf_dict[i] = [(0, 1, 1),(0, 1, 1, 12)]\n",
    "\n",
    "    normalization_false = ['PR', 'PB', 'DF']\n",
    "    if(uf in normalization_false):\n",
    "        normalization = False\n",
    "    else:\n",
    "        normalization = True\n",
    "\n",
    "    sarimax, df_test = sarimax_algorithm(xtrain, xtest, target, interval_start, interval_end, order=uf_dict[uf][0], seasonal_order=uf_dict[uf][1], normalization= normalization)\n",
    "    \n",
    "    return sarimax, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dc69e",
   "metadata": {},
   "source": [
    "## Métricas de Validação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58463eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics(y_true, y_pred, results):\n",
    "    \"\"\" Performs the model's validation metrics (Mean Absolute Percentage Error & Root Mean Square Error & Mean Absolute Error).\n",
    "\n",
    "        Args:\n",
    "            y_true (object/spreadsheet): The dataset under analysis.\n",
    "            y_pred (object/spreadsheet): The dataset under analysis.\n",
    "\n",
    "        Returns:\n",
    "            The results of adf test.\n",
    "    \"\"\"   \n",
    "    \n",
    "    _mape = np.mean(np.abs((y_true - y_pred) / y_true )) * 100\n",
    "    _rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    _mae = np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "    results.writelines('MAPE: {:.2f}, RMSE: {:.2f}, MAE: {:.2f}'.format(_mape, _rmse, _mae) + '\\n\\n')\n",
    "    \n",
    "    return 'MAPE: {:.2f}, RMSE: {:.2f}, MAE: {:.2f}'.format(_mape, _rmse, _mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddabf9e",
   "metadata": {},
   "source": [
    "## Gráfico com comportamento da variável a ser predita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5472993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_behavior(dataset, target, PATH, uf):\n",
    "    \"\"\" Create the plot based in the target variable that wants to predict.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "\n",
    "        Returns:\n",
    "            A plot with target behavior.\n",
    "    \"\"\"  \n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "    sns.lineplot(data=dataset, x=dataset['mes'].dt.strftime('%Y%m'), y=target)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Consumo Total')\n",
    "    \n",
    "    plt.savefig(PATH + '/Consumo_Total_' + uf + '.png')\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a37c51",
   "metadata": {},
   "source": [
    "## Gráfico com comportamento da variável a ser predita, da média móvel e do desvio padrão móvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c3f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moving_average(dataset, target, window, PATH, uf):\n",
    "    \"\"\" Create the plot based in the target's moving average.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "            window (int): The moving average window.\n",
    "\n",
    "        Returns:\n",
    "            A plot with target behavior, target's moving average and its moving standard deviation.\n",
    "    \"\"\"     \n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "    x = dataset['mes']\n",
    "    y = dataset[target]\n",
    "    \n",
    "    mm3 = dataset[target].rolling(window).mean()\n",
    "    rolling_std = dataset[target].rolling(window).std()\n",
    "    \n",
    "    plt.plot(x, y, label='Real', color='#3CADF2')\n",
    "    plt.plot(x, mm3, label='Média Móvel de ' + str(window), color='red')\n",
    "    plt.plot(x, rolling_std, label='Std de ' + str(window), color='green')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.savefig(PATH + '/Media_Movel_' + uf + '.png')\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c26ea8",
   "metadata": {},
   "source": [
    "## Gráficos de decomposição da série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9c2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serie_decompose(dataset, target, PATH, uf):\n",
    "    \"\"\" Create the plots based in serie decomposition into trend, sazonality and residues.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The target under analysis.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with serie's decompose and the decompose data.\n",
    "    \"\"\"     \n",
    "    \n",
    "    decompose = dataset.copy()\n",
    "    decompose.set_index(\"mes\", inplace=True)\n",
    "    \n",
    "    if(uf == 'CE'):\n",
    "        decompose_data = seasonal_decompose(decompose[target], model=\"aditive\")\n",
    "    else:\n",
    "        decompose_data = seasonal_decompose(decompose[target], model=\"multiplicative\")\n",
    "    \n",
    "    #fig = plt.figure(figsize=(20, 6))\n",
    "    fig = decompose_data.plot()\n",
    "    fig.set_size_inches((12, 12))\n",
    "    \n",
    "    plt.savefig(PATH + '/Serie_Decompose_' + uf + '.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return decompose_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cbabe",
   "metadata": {},
   "source": [
    "## Gráficos de diferenciação, autocorrelação (acf) e autocorrelação parcial (pacf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95062447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_acf_pacf(dataset, target, PATH, uf):\n",
    "    \"\"\" Create differentiation, autocorrelation and parcial autocorrelation plot.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The dataset under analysis.\n",
    "            target (string): The name of target column under analysis.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with differentiation, autocorrelation and parcial autocorrelation plot.\n",
    "    \"\"\"     \n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15,15))\n",
    "\n",
    "    # Original Series\n",
    "    axes[0, 0].plot(dataset[target]); axes[0, 0].set_title('Original Series')\n",
    "    fig = sm.graphics.tsa.plot_acf(dataset[target], lags=40, ax=axes[0,1])\n",
    "    fig = sm.graphics.tsa.plot_pacf(dataset[target], lags=20, ax=axes[0,2])\n",
    "\n",
    "    # 1st Order Differencing Series\n",
    "    axes[1, 0].plot(dataset[target].diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "    fig = sm.graphics.tsa.plot_acf(dataset[target].diff().dropna(), lags=40, ax=axes[1,1])\n",
    "    fig = sm.graphics.tsa.plot_pacf(dataset[target].diff().dropna(), lags=20, ax=axes[1,2])\n",
    "\n",
    "    # 2st Order Differencing Series\n",
    "    axes[2, 0].plot(dataset[target].diff().diff()); axes[2, 0].set_title('2st Order Differencing')\n",
    "    fig = sm.graphics.tsa.plot_acf(dataset[target].diff().diff().dropna(), lags=40, ax=axes[2,1])\n",
    "    fig = sm.graphics.tsa.plot_pacf(dataset[target].diff().diff().dropna(), lags=20, ax=axes[2,2])\n",
    "    \n",
    "    plt.savefig(PATH + '/Serie_ACF_PACF_' + uf + '.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f8a10",
   "metadata": {},
   "source": [
    "## Gráfico Real vs Predito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1192f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict_x_real(test_dataset, target, prediction, PATH, uf):\n",
    "    \"\"\" Create real vs predict plot.\n",
    "\n",
    "        Args:\n",
    "            test_dataset (object/spreadsheet): The test dataset under analysis.\n",
    "            target (string): The name of target column under analysis.\n",
    "            prediction (string): The name of column with predicted values.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with the comparison of real vs predict.\n",
    "    \"\"\"     \n",
    "\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "    x = test_dataset[~test_dataset[target].isna()].index\n",
    "    y = test_dataset[~test_dataset[target].isna()][target]\n",
    "    p = test_dataset[~test_dataset[target].isna()][prediction]\n",
    "    plt.plot(x, y, label='Real', color='#3CADF2')\n",
    "    plt.plot(x, p, label='Predicted', color='red')\n",
    "\n",
    "    for a, b in zip(x, y):\n",
    "        plt.annotate(\"{:.2f}\".format(b), (a, b), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    for a, b in zip(x, p):\n",
    "        plt.annotate(\"{:.2f}\".format(b), (a, b), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.savefig(PATH + '/PredictedxReal_' + uf + '.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98ea6c",
   "metadata": {},
   "source": [
    "## Gráfico com o comportamento do ano predito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b6f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_behavior(test_dataset, target, prediction, PATH, uf):\n",
    "    \"\"\" Create real/predict plot from a year.\n",
    "\n",
    "        Args:\n",
    "            test_dataset (object/spreadsheet): The test dataset under analysis.\n",
    "            target (string): The name of target column under analysis.\n",
    "            prediction (string): The name of column with predicted values.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with year behavior.\n",
    "    \"\"\"         \n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "    x = test_dataset.index\n",
    "    y = test_dataset[target]\n",
    "    p = test_dataset[prediction]\n",
    "    plt.plot(x, y, label='Real', color='#3CADF2')\n",
    "    plt.plot(x, p, label='Predicted', color='red')\n",
    "\n",
    "    for a, b in zip(x, y):\n",
    "        plt.annotate(\"{:.2f}\".format(b), (a, b), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    for a, b in zip(x, p):\n",
    "        plt.annotate(\"{:.2f}\".format(b), (a, b), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.savefig(PATH + '/Year_Behavior_' + uf + '.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7733e82",
   "metadata": {},
   "source": [
    "## Gráfico com o comportamento da série original e predita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1f01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_serie_behavior(dataset, test_dataset, interval_start, target, prediction, PATH, uf):\n",
    "    \"\"\" Create serie's behavior plot.\n",
    "\n",
    "        Args:\n",
    "            dataset (object/spreadsheet): The full dataset under analysis.\n",
    "            test_dataset (object/spreadsheet): The test dataset under analysis.\n",
    "            interval_start (int): The start index of the test interval.\n",
    "            target (string): The name of target column under analysis.\n",
    "            prediction (string): The name of column with predicted values.\n",
    "            title (string): The title wants to put in the plot.\n",
    "            \n",
    "        Returns:\n",
    "            A plot with year behavior.\n",
    "    \"\"\"           \n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = pd.concat([dataset[:interval_start].set_index('mes'), test_dataset])\n",
    "    df_final.reset_index(inplace = True)\n",
    "\n",
    "    x = df_final['mes'].dt.date\n",
    "    _real = df_final[target]\n",
    "    _pred = df_final[prediction]\n",
    "\n",
    "    plt.plot(x, _real, label='Real', color='#3CADF2')\n",
    "    plt.plot(x, _pred, label='Predicted', color='red')\n",
    "    plt.legend()\n",
    "    plt.title(\"PREVISÃO PARA O SEGUNDO SEMESTRE DO ANO DE 2022 EM \" + uf)\n",
    "\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.savefig(PATH + '/Serie_Behavior_' + uf + '.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fe6cf",
   "metadata": {},
   "source": [
    "# Função principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6b2eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Coloque aqui o caminho ao qual os arquivos se encontram\n",
    "    PATH = '../Dados/Armarios/Bases/'\n",
    "\n",
    "    ufs = ['SP', 'RJ', 'MG', 'ES', 'PR', 'SC', 'RS', 'DF', 'MT', 'MS', 'GO', 'PB', 'PE', 'RN', 'CE', 'SE', 'BA', 'AL']\n",
    "    \n",
    "    # Estados cujo histórico para o modelo não começa em 2017\n",
    "    uf_exceptions = ['MS', 'MT', 'DF', 'PB']\n",
    "    \n",
    "    for uf in ufs:\n",
    "        \n",
    "        print(\"Executando previsão para o estado de \" + uf)\n",
    "        \n",
    "        # Seleciona o arquivo no qual o histórico do estado se encontra\n",
    "        df = file_selection(uf, PATH)\n",
    "        \n",
    "        # Cria pastas para cada estado\n",
    "        temporary_PATH = PATH + uf\n",
    "        if not os.path.exists(temporary_PATH):\n",
    "            os.mkdir(temporary_PATH)\n",
    "        \n",
    "        # Arquivo de log estatístico\n",
    "        output_file = open(temporary_PATH + '/log_statistics.txt', 'a')\n",
    "        \n",
    "        # Plota o comportamento do histórico da variável a ser predita\n",
    "        plot_target_behavior(df,'consumoacumuladodomes_soma', temporary_PATH, uf)\n",
    "        \n",
    "        # Executa o teste de estacionariedade\n",
    "        adf_test(df['consumoacumuladodomes_soma'], output_file)\n",
    "        \n",
    "        # Plota o comportamento do históricoa média móvel da variável a ser predita\n",
    "        plot_moving_average(df,'consumoacumuladodomes_soma', 3, temporary_PATH, uf)\n",
    "        \n",
    "        # Executa a decomposição da série temporal em tendência, sazonalidade e resíduos\n",
    "        decompose_data = serie_decompose(df,'consumoacumuladodomes_soma', temporary_PATH, uf)\n",
    "        \n",
    "        # Plota o comportamento do acf e pacf da variável a ser predita\n",
    "        plot_diff_acf_pacf(df, 'consumoacumuladodomes_soma', temporary_PATH, uf)\n",
    "\n",
    "        # Executa a diferenciação da série e o teste de estacionariedade na série diferenciada\n",
    "        df_diff = serie_differentiation(df,'consumoacumuladodomes_soma', output_file, temporary_PATH, uf)\n",
    "\n",
    "        # Executa a autocorrelação da série temporal em 1,3,6,9 ou 12 meses\n",
    "        autocorrelation_lag(df, 'consumoacumuladodomes_soma', output_file)\n",
    "        \n",
    "        # Seleção do período utilizado nos estados cujo histórico para o modelo não começa em 2017\n",
    "        if(uf in uf_exceptions):\n",
    "            \n",
    "            if(uf == 'DF'):\n",
    "                df = df.reset_index()\n",
    "                df = df[['mes', 'consumoacumuladodomes_soma']].iloc[48:,:]\n",
    "            else:\n",
    "                df = df.reset_index()\n",
    "                df = df[['mes', 'consumoacumuladodomes_soma']].iloc[12:,]\n",
    "                \n",
    "        \n",
    "        # Divisão em treino e teste utilizando o date_split como primeira data do conjunto de teste e o date_end como a última data de teste\n",
    "        date_split = dt.datetime(2022, 1, 1)\n",
    "        date_end = dt.datetime(2022, 12, 1)\n",
    "\n",
    "        # '2022-06-01' (início onde não tem dados na base), 7 (prever 7 períodos para frente), 'M' (M = meses)\n",
    "        # Prever de junho/22 7 períodos para frente, ou seja, até dezembro/22\n",
    "        xtrain, xtest, interval_start, interval_end, dataset = train_test_split_data(df, 'consumoacumuladodomes_soma', '2022-06-01', 7, 'M', date_split, date_end, output_file)\n",
    "        \n",
    "        # Execução dos modelos de cada estado, salvando as métricas de validação (calculadas a partir das datas de \n",
    "        # janeiro à maio de 2022, datas nas quais o faturamento está fechado e temos os valores na base) do modelo no arquivo\n",
    "        results = open(temporary_PATH + '/predictions_validation.txt', 'a')\n",
    "        sarimax, df_test = uf_models(uf, xtrain, xtest, 'consumoacumuladodomes_soma', interval_start, interval_end)\n",
    "        \n",
    "        y_true = df_test[~df_test['consumoacumuladodomes_soma'].isna()]['consumoacumuladodomes_soma'].values\n",
    "        y_pred = df_test[~df_test['consumoacumuladodomes_soma'].isna()]['pred'].values\n",
    "    \n",
    "        metrics = validation_metrics(y_true, y_pred, results)\n",
    "        \n",
    "        # Plota o comportamento dos valores reais vs valores preditos\n",
    "        plot_predict_x_real(df_test, 'consumoacumuladodomes_soma', 'pred', temporary_PATH, uf)\n",
    "        \n",
    "        # Plota o comportamento dos valores reais vs valores preditos no ano de 2022\n",
    "        plot_year_behavior(df_test, 'consumoacumuladodomes_soma', 'pred', temporary_PATH, uf)\n",
    "        \n",
    "        # Plota o comportamento do histórico do estado, com a curva de comportamento dos valores reais (em azul) e \n",
    "        # a curva de comportamento dos valores preditos (em vermelho)\n",
    "        plot_serie_behavior(df, df_test, interval_start, 'consumoacumuladodomes_soma', 'pred', temporary_PATH, uf)\n",
    "        \n",
    "        # Salva os valores de teste reais e preditos no arquivo\n",
    "        df_test.to_csv(results, index = 'False', line_terminator='\\n')\n",
    "        \n",
    "        # Fecha o arquivo de log e de resultados\n",
    "        output_file.close()\n",
    "        results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ba7c6",
   "metadata": {},
   "source": [
    "## Execução da função principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac39ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando previsão para o estado de SP\n",
      "Executando previsão para o estado de RJ\n",
      "Executando previsão para o estado de MG\n",
      "Executando previsão para o estado de ES\n",
      "Executando previsão para o estado de PR\n",
      "Executando previsão para o estado de SC\n",
      "Executando previsão para o estado de RS\n",
      "Executando previsão para o estado de DF\n",
      "Executando previsão para o estado de MT\n",
      "Executando previsão para o estado de MS\n",
      "Executando previsão para o estado de GO\n",
      "Executando previsão para o estado de PB\n",
      "Executando previsão para o estado de PE\n",
      "Executando previsão para o estado de RN\n",
      "Executando previsão para o estado de CE\n",
      "Executando previsão para o estado de SE\n",
      "Executando previsão para o estado de BA\n",
      "Executando previsão para o estado de AL\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd9ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
